{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_players(input_dataset):\n",
    "    # Code to Rearrange the players and make the 'home_4' column vacant\n",
    "    home_team = ['home_0', 'home_1', 'home_2', 'home_3']\n",
    "    for i in range(input_dataset.shape[0]):\n",
    "        for players in home_team:\n",
    "            if input_dataset.loc[i, players] == '?':\n",
    "                input_dataset.loc[i, players] = input_dataset.loc[i, 'home_4']\n",
    "    input_dataset.drop(['home_4'], inplace=True, axis = 1)\n",
    "    return input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_players_list_for_current_team(season, home_team_name):\n",
    "    if season > 2015:\n",
    "        season = 2015\n",
    "    with open('models/players_list_by_model/player_list_' + str(season) + '.json', 'r') as infile:\n",
    "        players_file = json.load(infile)\n",
    "\n",
    "    return players_file[str(season)][home_team_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_mappings_for_current_season(season):\n",
    "    if season > 2015:\n",
    "        season = 2015\n",
    "    with open('models/player_mappings/player_mapping_' + str(season) + '.json', 'r') as infile:\n",
    "        players_mapping = json.load(infile)\n",
    "\n",
    "    return players_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_based_on_season(season):\n",
    "    if season > 2015:\n",
    "        season = 2015\n",
    "    embedding_model = joblib.load('models/player_embeddings/player_embeddings_' + str(season) + '.pkl')\n",
    "    rf_model = joblib.load('models/random_forest/rf_model_' + str(season) + '.pkl')\n",
    "    rf_scalar = joblib.load('models/random_forest/rf_scalar_' + str(season) + '.pkl')\n",
    "    rf_pca = joblib.load('models/random_forest/rf_pca_' + str(season) + '.pkl')\n",
    "    knn_model = joblib.load('models/knn/knn_model_' + str(season) + '.pkl')\n",
    "    knn_scalar = joblib.load('models/knn/knn_scalar_' + str(season) + '.pkl')\n",
    "    knn_pca = joblib.load('models/knn/knn_pca_' + str(season) + '.pkl')\n",
    "    return embedding_model, rf_model, rf_scalar, rf_pca, knn_model, knn_scalar, knn_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_embeddings(embedding_model, home_team_players, away_team_players, player_mappings):\n",
    "    # Storing the weights which are the 32-dimensional feature vectors for the home players in the dictionary.\n",
    "    home_weights=embedding_model.get_layer('home_embedding').get_weights()[0]\n",
    "    home_player_weights = {index: array for index, array in enumerate(home_weights)}\n",
    "    \n",
    "    # Storing the weights which are the 32-dimensional feature vectors for the away players in the dictionary.\n",
    "    away_weights=embedding_model.get_layer('away_embedding').get_weights()[0]\n",
    "    away_player_weights = {index: array for index, array in enumerate(away_weights)}\n",
    "\n",
    "    home_team_players_embeddings = []\n",
    "    for player in home_team_players:\n",
    "        player_code = player_mappings.get(player)\n",
    "        if player_code is None:\n",
    "            # Player statistics not available in existing training dataset\n",
    "            # FIX ME - player mapping not found for debutant players\n",
    "            player_code = 0\n",
    "            # raise ValueError(f\"Player not found in mapping: {player}\")\n",
    "\n",
    "        embedding = home_player_weights.get(player_code)\n",
    "        if embedding is None:\n",
    "            raise ValueError(f\"No embedding found for player: {player}\")\n",
    "\n",
    "        home_team_players_embeddings.append(embedding)\n",
    "\n",
    "    away_team_players_embeddings = []\n",
    "    for player in away_team_players:\n",
    "        player_code = player_mappings.get(player)\n",
    "        if player_code is None:\n",
    "            # Player statistics not available in existing training dataset\n",
    "            # FIX ME - player mapping not found for debutant players\n",
    "            player_code = 0\n",
    "            # raise ValueError(f\"Player not found in mapping: {player}\")\n",
    "\n",
    "        embedding = away_player_weights.get(player_code)\n",
    "        if embedding is None:\n",
    "            raise ValueError(f\"No embedding found for player: {player}\")\n",
    "\n",
    "        away_team_players_embeddings.append(embedding)\n",
    "\n",
    "    return home_team_players_embeddings, away_team_players_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_5_highest_probable_players(season, home_team, home_players_selected, away_players_selected):\n",
    "    player_pool = list(set(get_players_list_for_current_team(season, home_team)) - set(home_players_selected))\n",
    "    player_mapping = get_player_mappings_for_current_season(season)\n",
    "    embedding_model, rf_model, rf_scalar, rf_pca, knn_model, knn_scalar, knn_pca = read_model_based_on_season(season)\n",
    "    home_player_embeddings, away_player_embeddings = get_player_embeddings(embedding_model, home_players_selected, away_players_selected, player_mapping)\n",
    "    candidate_player_embeddings, empty_embeddings = get_player_embeddings(embedding_model, player_pool, [], player_mapping)\n",
    "    X_input = []\n",
    "    for candidates in candidate_player_embeddings:\n",
    "        combinations = home_player_embeddings + [candidates] + away_player_embeddings\n",
    "        X_input.append(np.concatenate(combinations))\n",
    "    \n",
    "    X_input_flat = np.vstack(X_input)\n",
    "    expected_shape = len(home_player_embeddings[0]) * len(home_player_embeddings) + \\\n",
    "                    len(away_player_embeddings[0]) * len(away_player_embeddings) + \\\n",
    "                    len(candidate_player_embeddings[0])\n",
    "\n",
    "    if X_input_flat.shape[1] != expected_shape:\n",
    "        raise ValueError(f\"Incorrect feature dimension. Expected {expected_shape}, got {X_input_flat.shape[1]}\")\n",
    "\n",
    "    X_flat_scaled = rf_scalar.transform(X_input_flat)\n",
    "\n",
    "    # Apply PCA to reduce dimensionality while preserving 95% of variance\n",
    "    X_flat_reduced = rf_pca.transform(X_flat_scaled)\n",
    "\n",
    "    rf_predictions = rf_model.predict(X_flat_reduced)\n",
    "    rf_probabilities = rf_model.predict_proba(X_flat_reduced)\n",
    "    print(len(rf_probabilities), len(player_pool))\n",
    "    rf_results = []\n",
    "    for i, player in enumerate(player_pool):\n",
    "        rf_results.append({'player_name': player, 'win_probability': rf_probabilities[i][1]})\n",
    "\n",
    "    rf_results.sort(key=lambda x: x['win_probability'], reverse=True)\n",
    "    \n",
    "\n",
    "    X_flat_scaled = knn_scalar.transform(X_input_flat)\n",
    "\n",
    "    # Apply PCA to reduce dimensionality while preserving 95% of variance\n",
    "    X_flat_reduced = knn_pca.transform(X_flat_scaled)\n",
    "\n",
    "    knn_predictions = knn_model.predict(X_flat_reduced)\n",
    "    knn_probabilities = knn_model.predict_proba(X_flat_reduced)\n",
    "    knn_results = []\n",
    "    for i, player in enumerate(player_pool):\n",
    "        knn_results.append({'player_name': player, 'win_probability': knn_probabilities[i][1]})\n",
    "\n",
    "    knn_results.sort(key=lambda x: x['win_probability'], reverse=True)\n",
    "\n",
    "    return rf_results, knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(season, home_team, home_players_selected, away_players_selected):\n",
    "    player_pool = list(set(get_players_list_for_current_team(season, home_team)) - set(home_players_selected))\n",
    "    player_mapping = get_player_mappings_for_current_season(season)\n",
    "    embedding_model, rf_model, rf_scalar, rf_pca, knn_model, knn_scalar, knn_pca = read_model_based_on_season(season)\n",
    "    home_player_embeddings, away_player_embeddings = get_player_embeddings(embedding_model, home_players_selected, away_players_selected, player_mapping)\n",
    "    candidate_player_embeddings, empty_embeddings = get_player_embeddings(embedding_model, player_pool, [], player_mapping)\n",
    "    X_input = []\n",
    "    for candidates in candidate_player_embeddings:\n",
    "        combinations = home_player_embeddings + [candidates] + away_player_embeddings\n",
    "        X_input.append(np.concatenate(combinations))\n",
    "    \n",
    "    X_input_flat = np.vstack(X_input)\n",
    "    expected_shape = len(home_player_embeddings[0]) * len(home_player_embeddings) + \\\n",
    "                    len(away_player_embeddings[0]) * len(away_player_embeddings) + \\\n",
    "                    len(candidate_player_embeddings[0])\n",
    "\n",
    "    if X_input_flat.shape[1] != expected_shape:\n",
    "        raise ValueError(f\"Incorrect feature dimension. Expected {expected_shape}, got {X_input_flat.shape[1]}\")\n",
    "\n",
    "    X_flat_scaled = rf_scalar.transform(X_input_flat)\n",
    "\n",
    "    # Apply PCA to reduce dimensionality while preserving 95% of variance\n",
    "    X_flat_reduced = rf_pca.transform(X_flat_scaled)\n",
    "\n",
    "    rf_predictions = rf_model.predict(X_flat_reduced)\n",
    "    rf_probabilities = rf_model.predict_proba(X_flat_reduced)\n",
    "    rf_results = []\n",
    "    for i, player in enumerate(player_pool):\n",
    "        rf_results.append({'player_name': player, 'win_probability': rf_probabilities[i][1]})\n",
    "\n",
    "    rf_results.sort(key=lambda x: x['win_probability'], reverse=True)\n",
    "\n",
    "    X_flat_scaled = knn_scalar.transform(X_input_flat)\n",
    "\n",
    "    # Apply PCA to reduce dimensionality while preserving 95% of variance\n",
    "    X_flat_reduced = knn_pca.transform(X_flat_scaled)\n",
    "\n",
    "    knn_predictions = knn_model.predict(X_flat_reduced)\n",
    "    knn_probabilities = knn_model.predict_proba(X_flat_reduced)\n",
    "    knn_results = []\n",
    "    for i, player in enumerate(player_pool):\n",
    "        knn_results.append({'player_name': player, 'win_probability': knn_probabilities[i][1]})\n",
    "\n",
    "    knn_results.sort(key=lambda x: x['win_probability'], reverse=True)\n",
    "    return rf_results, knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_highest_probable_player(rf_results, knn_results):\n",
    "    rf_output = []\n",
    "    i = 0\n",
    "    rf_output.append(rf_results[0]['player_name'])\n",
    "    while (i < len(rf_results) - 1) and (rf_results[i]['win_probability'] == rf_results[i + 1]['win_probability']):\n",
    "        rf_output.append(rf_results[i + 1]['player_name'])\n",
    "        i += 1\n",
    "    knn_output = []\n",
    "    i = 0\n",
    "    knn_output.append(knn_results[0]['player_name'])\n",
    "    while (i < len(knn_results) - 1) and (knn_results[i]['win_probability'] == knn_results[i + 1]['win_probability']):\n",
    "        knn_output.append(knn_results[i + 1]['player_name'])\n",
    "        i += 1\n",
    "\n",
    "    return rf_output, knn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_5_highest_probable_players(rf_results, knn_results):\n",
    "    rf_output = []\n",
    "    i = 4\n",
    "    rf_output.append(rf_results[0]['player_name'])\n",
    "    rf_output.append(rf_results[1]['player_name'])\n",
    "    rf_output.append(rf_results[2]['player_name'])\n",
    "    rf_output.append(rf_results[3]['player_name'])\n",
    "    rf_output.append(rf_results[4]['player_name'])\n",
    "    while (i < len(rf_results) - 1) and (rf_results[i]['win_probability'] == rf_results[i + 1]['win_probability']):\n",
    "        rf_output.append(rf_results[i + 1]['player_name'])\n",
    "        i += 1\n",
    "    \n",
    "    knn_output = []\n",
    "    i = 4\n",
    "    knn_output.append(knn_results[0]['player_name'])\n",
    "    knn_output.append(knn_results[1]['player_name'])\n",
    "    knn_output.append(knn_results[2]['player_name'])\n",
    "    knn_output.append(knn_results[3]['player_name'])\n",
    "    knn_output.append(knn_results[4]['player_name'])\n",
    "    while (i < len(knn_results) - 1) and (knn_results[i]['win_probability'] == knn_results[i + 1]['win_probability']):\n",
    "        knn_output.append(knn_results[i + 1]['player_name'])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outputs(input_dataset, expected_output):\n",
    "    o1_count, o2_count = 0, 0\n",
    "    for i in range(input_dataset.shape[0]):\n",
    "        o1, o2 = predict(input_dataset.loc[i, 'season'], input_dataset.loc[i, 'home_team'], [input_dataset.loc[i, 'home_0'], input_dataset.loc[i, 'home_1'], input_dataset.loc[i, 'home_2'], input_dataset.loc[i, 'home_3']], [input_dataset.loc[i, 'away_0'], input_dataset.loc[i, 'away_1'], input_dataset.loc[i, 'away_2'], input_dataset.loc[i, 'away_3'], input_dataset.loc[i, 'away_4']])\n",
    "        o1, o2 = predict_highest_probable_player(o1, o2)\n",
    "        if expected_output.loc[i, 'removed_value'] in o1:\n",
    "            o1_count += 1\n",
    "        if expected_output.loc[i, 'removed_value'] in o2:\n",
    "            o2_count += 1\n",
    "        print(i, o1, o2, expected_output.loc[i, 'removed_value'] in o1, expected_output.loc[i, 'removed_value'] in o2, sep='\\t')\n",
    "    print(o1_count, o2_count, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_highest_probable_player() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m expected_output = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mtesting_dataset/NBA_test_labels.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m input_dataset = rearrange_players(input_dataset)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mgenerate_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[175]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_outputs\u001b[39m\u001b[34m(input_dataset, expected_output)\u001b[39m\n\u001b[32m      2\u001b[39m o1_count, o2_count = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(input_dataset.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     o1, o2 = \u001b[43mpredict_highest_probable_player\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseason\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhome_team\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhome_0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhome_1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhome_2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhome_3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maway_0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maway_1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maway_2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maway_3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maway_4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m expected_output.loc[i, \u001b[33m'\u001b[39m\u001b[33mremoved_value\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m o1:\n\u001b[32m      6\u001b[39m         o1_count += \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: predict_highest_probable_player() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "input_dataset = pd.read_csv(\"testing_dataset/NBA_test.csv\")\n",
    "expected_output = pd.read_csv(\"testing_dataset/NBA_test_labels.csv\")\n",
    "input_dataset = rearrange_players(input_dataset)\n",
    "generate_outputs(input_dataset, expected_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
